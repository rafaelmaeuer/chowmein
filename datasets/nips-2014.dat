Das Problem der Schätzung des Kernel-Mittelwerts in einem reproduzierenden Kernel-Hilbert-Raum (RKHS) ist insofern zentral für Kernel-Methoden, als es von klassischen Ansätzen verwendet wird (z.B. beim Zentrieren einer Kernel-PCA-Matrix), und es bildet auch den zentralen Inferenz-Schritt moderner Kernel-Methoden (z.B. kernel-basierte nicht-parametrische Tests), die auf der Einbettung von Wahrscheinlichkeitsverteilungen in RKHSs beruhen. Frühere Arbeiten [1] haben gezeigt, dass Schrumpfung bei der Konstruktion von âbesserenâ Schätzern des Kernmittelwertes als der empirische Schätzer helfen kann. Die vorliegende Arbeit untersucht die Konsistenz und Zulässigkeit der Schätzer in [1] und schlägt eine breitere Klasse von Schrumpfungsschätzern vor, die den empirischen Schätzer durch die Berücksichtigung geeigneter Basisfunktionen verbessern. Unter Verwendung der Kernel-PCA-Basis zeigen wir, dass einige dieser Schätzer mit Hilfe von Algorithmen zur spektralen Filterung konstruiert werden können, die sich unter einigen technischen Annahmen als konsistent erweisen. Unsere theoretische Analyse zeigt auch eine grundlegende Verbindung zum kernelbasierten supervidierten Lernframework. Die vorgeschlagenen Schätzer sind einfach zu implementieren und leisten in der Praxis gute Arbeit.
Die Probenahme aus hierarchischen Bayes'schen Modellen ist für MCMC-Methoden aufgrund der starken Korrelationen zwischen den Modellparametern und den Hyperparametern oft schwierig. Neuere vielfältige Hamiltonian-Monte-Carlo-Methoden (RMHMC) nach Riemann haben in diesem Umfeld erhebliche potenzielle Vorteile, sind aber rechnerisch teuer. Wir stellen eine neue RMHMC-Methode vor, die wir als semi-trennbares Hamiltonian Monte Carlo bezeichnen und die eine speziell entworfene Massenmatrix verwendet, die es dem gemeinsamen Hamiltonian über Modellparameter und Hyperparameter erlaubt, sich in zwei einfachere Hamiltonianer zu zerlegen. Diese Struktur wird durch einen neuen Integrator ausgenutzt, den wir den alternierenden blockweisen Leapfrog-Algorithmus nennen. Die sich daraus ergebende Methode kann schneller gemischt werden als die einfachere Gibbs-Abtastung und ist gleichzeitig einfacher und effizienter als frühere Instanzen von RMHMC.
Dieses Papier beschreibt ein Parameter-Server-Framework der dritten Generation für verteiltes maschinelles Lernen. Dieses Framework bietet zwei Lockerungen, um Systemleistung und Algorithmus-Effizienz auszubalancieren. Wir schlagen einen neuen Algorithmus vor, der sich dieses Framework zunutze macht, um nicht-konvexe, nicht-glatte Probleme mit Konvergenzgarantien zu lösen. Wir stellen eine eingehende Analyse von zwei groß angelegten maschinellen Lernproblemen vor, die von der $\ell_1$-regularisierten logistischen Regression auf CPUs bis zur Rekonstruktion von ICA auf GPUs reichen, wobei 636TB reale Daten mit Hunderten von Milliarden von Stichproben und Dimensionen verwendet werden. Anhand dieser Beispiele zeigen wir, dass das Parameter-Server-Framework eine effektive und unkomplizierte Möglichkeit darstellt, maschinelles Lernen auf größere Probleme und Systeme zu skalieren, als dies bisher möglich war.
Dirichlet-Prozessmischung von Gaussians (DPMG) wurde in der Literatur für Clustering- und Dichteschätzprobleme verwendet. Viele Daten aus der realen Welt weisen jedoch Clusterverteilungen auf, die von einem einzelnen Gaußschen nicht erfasst werden können. Die Modellierung solcher Datensätze durch DPMG erzeugt mehrere Fremdcluster, selbst wenn die Cluster relativ gut definiert sind. Hier stellen wir die unendliche Mischung von unendlichen Gaußschen Mischungen (I2GMM) für eine flexiblere Modellierung von Datensätzen mit schiefen und multimodalen Clusterverteilungen vor. Anstatt, wie im Standard-DPMG-Modell, eine einzige Gaußsche Mischung für jeden Cluster zu verwenden, verwendet das generative Modell von I2GMM eine einzige DPMG für jeden Cluster. Die einzelnen DPMGs sind durch die Zentrierung ihrer Basisverteilungen an den Atomen einer übergeordneten DP-Priorität miteinander verbunden. Die Inferenz wird durch einen kollabierten Gibbs-Sampler durchgeführt, der auch eine partielle Parallelisierung ermöglicht. Experimentelle Ergebnisse mit mehreren künstlichen und realen Datensätzen lassen vermuten, dass das vorgeschlagene I2GMM-Modell Cluster genauer vorhersagen kann als bestehende Bayes- und Gibbs-Stichprobenversionen von DPMG.
In vielen wichtigen Anwendungen des maschinellen Lernens unterscheidet sich die Quellverteilung, die zur Schätzung eines probabilistischen Klassifikators verwendet wird, von der Zielverteilung, auf der der Klassifikator zur Vorhersage verwendet werden soll. Aufgrund ihrer asymptotischen Eigenschaften ist die stichprobengewichtete Verlustminimierung eine häufig verwendete Technik, um mit diesem Unterschied umzugehen. Angesichts endlicher Mengen markierter Quelldaten leidet diese Technik jedoch unter signifikanten Schätzfehlern bei Einstellungen mit großem Stichprobenauswahl-Bias. Wir entwickeln ein Rahmenwerk zum robusten Erlernen eines probabilistischen Klassifikators, der sich unter Verwendung einer Minimax-Schätzformulierung an verschiedene Stichprobenauswahlverzerrungen anpasst. Unser Ansatz erfordert nur genaue Schätzungen der Statistiken unter der Quellenverteilung und ist ansonsten so robust wie möglich gegenüber unbekannten Eigenschaften der bedingten Label-Verteilung, außer wenn explizite Verallgemeinerungsannahmen einbezogen werden. Wir demonstrieren das Verhalten und die Wirksamkeit unseres Ansatzes bei synthetischen und binären UCI-Klassifikationsaufgaben.
Die Auswahl einer kleinen informativen Teilmenge aus einem gegebenen Datensatz, auch Spaltenstichproben genannt, hat beim maschinellen Lernen viel Aufmerksamkeit erregt. Für die Einbeziehung von 